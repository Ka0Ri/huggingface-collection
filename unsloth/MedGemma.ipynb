{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9592e546",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/AISeed/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 2 files: 100%|██████████| 2/2 [01:02<00:00, 31.40s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:28<00:00, 14.02s/it]\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "/data/AISeed/.venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:194: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
      "  warnings.warn(\n",
      "skipping cudagraphs due to skipping cudagraphs due to multiple devices: device(type='cuda', index=0), device(type='cuda', index=3), device(type='cuda', index=1), device(type='cuda', index=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, based on the provided chest X-ray image, here's a description:\n",
      "\n",
      "**Overall Impression:**\n",
      "\n",
      "The image shows a normal chest X-ray. The heart size appears within normal limits. The lungs are clear, with no obvious consolidation, effusions, or masses. The mediastinum is unremarkable. The bony structures of the rib cage and clavicles are intact.\n",
      "\n",
      "**Specific Findings:**\n",
      "\n",
      "*   **Heart:** The heart size appears to be within normal limits. The cardiothoracic ratio (the ratio of the heart's width to the chest's width) is likely less than 0.5, which is a good sign.\n",
      "*   **Lungs:** The lungs are clear bilaterally. There are no obvious signs of pneumonia, pulmonary edema, or pleural effusions. The lung markings are normal.\n",
      "*   **Mediastinum:** The mediastinum (the space between the lungs containing the heart, great vessels, trachea, and esophagus) appears\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "\n",
    "model_id = \"google/medgemma-4b-it\"\n",
    "\n",
    "model = AutoModelForImageTextToText.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    cache_dir=\"/data/AISeed/huggingface\",\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "# Image attribution: Stillwaterising, CC0, via Wikimedia Commons\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/c/c8/Chest_Xray_PA_3-8-2010.png\"\n",
    "image = Image.open(requests.get(image_url, headers={\"User-Agent\": \"example\"}, stream=True).raw)\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": [{\"type\": \"text\", \"text\": \"You are an expert radiologist.\"}]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"Describe this X-ray\"},\n",
    "            {\"type\": \"image\", \"image\": image}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "inputs = processor.apply_chat_template(\n",
    "    messages, add_generation_prompt=True, tokenize=True,\n",
    "    return_dict=True, return_tensors=\"pt\"\n",
    ").to(model.device, dtype=torch.bfloat16)\n",
    "\n",
    "input_len = inputs[\"input_ids\"].shape[-1]\n",
    "\n",
    "with torch.inference_mode():\n",
    "    generation = model.generate(**inputs, max_new_tokens=200, do_sample=False)\n",
    "    generation = generation[0][input_len:]\n",
    "\n",
    "decoded = processor.decode(generation, skip_special_tokens=True)\n",
    "print(decoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
