{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6788adff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "870e006484a6419c9f7e9918f1db8c2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The image depicts a close-up view of a vibrant pink flower, which appears to be a cosmos flower, surrounded by other flowers and plants in a garden setting. The cosmos flower is the central focus of the image, with its petals fully open and exhibiting a soft, delicate texture. The petals are a bright, almost neon pink color, with a slight gradient towards the edges, giving the flower a radiant appearance.\n",
      "\n",
      "In the center of the cosmos flower, there is a small insect, likely a bee, which is actively collecting nectar. The bee is positioned on the flower's central part, surrounded by the flower's petals. The\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the pipeline with a VLM\n",
    "pipe = pipeline(\"image-text-to-text\", \"HuggingFaceTB/SmolVLM2-2.2B-Instruct\", device_map=\"auto\", torch_dtype=torch.bfloat16)\n",
    "\n",
    "# Define your conversation with an image\n",
    "messages = [\n",
    "     {\n",
    "         \"role\": \"user\",\n",
    "         \"content\": [\n",
    "             {\n",
    "                 \"type\": \"image\",\n",
    "                 \"image\": \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/bee.jpg\",\n",
    "             },\n",
    "             {\"type\": \"text\", \"text\": \"Describe this image.\"},\n",
    "         ],\n",
    "     }\n",
    " ]\n",
    "\n",
    "outputs = pipe(text=messages, max_new_tokens=60, return_full_text=False)\n",
    "\n",
    "# Generate response - pipeline handles multimodal inputs automatically\n",
    "response = pipe(messages, max_new_tokens=128, temperature=0.7)\n",
    "\n",
    "print(response[0]['generated_text'][-1]['content'])  # Print the model's description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ec0137d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "\n",
    "# Set the path before importing HF libraries\n",
    "os.environ[\"HF_HOME\"] = \"/media/aiseed/AISeed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "895b8474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c911b854e1548a9b086f9542c6ea134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aeb57e1672946488116afb7cc94866a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ee578dee91d4505aa6e14ac8ccdc15e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.03G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cc96bd6cd554bcda59b61ab5d679c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9d35dbf04ef4fc086e4984bb786cdd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/136 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf896f77ff454bf692cd3374fb40b33b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processor_config.json:   0%|          | 0.00/67.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b669ce7c275a463992688ec4f49f1e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.json:   0%|          | 0.00/430 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbf032c2224845739828878ea9509d3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/599 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6680475f555c4fef9c83a96f6edce305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d21eeb68f484405a55d6c52b2311a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "010858b3f80b4b25952e50ced8efe33a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50301aa92f9d413a9d49fed449163abc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2849d7bb28064cbbaeb82331c23efee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a9667ec0bcc48708322a6a86237386f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/868 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoProcessor, AutoModelForImageTextToText, BitsAndBytesConfig\n",
    "from transformers.image_utils import load_image\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Quantization for efficiency\n",
    "quant_config = BitsAndBytesConfig(load_in_4bit=True)\n",
    "model_name = \"HuggingFaceTB/SmolVLM2-2.2B-Instruct\"\n",
    "model = AutoModelForImageTextToText.from_pretrained(model_name, quantization_config=quant_config).to(device)\n",
    "processor = AutoProcessor.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8686b834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image is a beautiful representation of nature's beauty. It features a bee, a symbol of pollination and ecosystem health, resting on a vibrant pink flower. The flower is surrounded by other flowers of various colors, including red and yellow, which add a splash of color to the scene. The bee is positioned in the center of the image, surrounded by the flowers, creating a sense of harmony and balance. The background is blurred, suggesting a natural setting, possibly a garden or a wildflower field. The image captures the essence of pollination and the interconnectedness of species in the ecosystem.\n"
     ]
    }
   ],
   "source": [
    "# Load image\n",
    "image_url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/bee.jpg\"\n",
    "image = load_image(image_url)\n",
    "\n",
    "# Create input messages\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"text\", \"text\": \"Can you describe the image?\"}\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "# Prepare inputs\n",
    "prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "inputs = processor(text=prompt, images=[image], return_tensors=\"pt\")\n",
    "inputs = inputs.to(device)\n",
    "\n",
    "# Generate outputs\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=500)\n",
    "generated_texts = processor.batch_decode(\n",
    "    generated_ids,\n",
    "    skip_special_tokens=True,\n",
    ")[0]\n",
    "\n",
    "# Extract only the assistant response\n",
    "assistant_response = generated_texts.split(\"Assistant:\")[-1].strip()\n",
    "\n",
    "print(assistant_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
