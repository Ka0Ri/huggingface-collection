{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ac63b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "\n",
    "# Set the path before importing HF libraries\n",
    "os.environ[\"HF_HOME\"] = \"/media/aiseed/AISeed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c6e1f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8f8ad64c8164a65b3eded5075eb7e1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': '<think>\\n'\n",
      "            'Okay, the user is asking, \"How many helicopters can a human eat '\n",
      "            'in one sitting?\" That\\'s a pretty funny question, but I need to '\n",
      "            'approach it seriously. Let me break it down.\\n'\n",
      "            '\\n'\n",
      "            'First, helicopters are large, heavy, and not meant to be eaten. '\n",
      "            \"They're made of metal, plastic, and other materials, not food. \"\n",
      "            \"So, from a biological perspective, humans can't eat helicopters \"\n",
      "            \"because they're not edible. But the user might be looking for a \"\n",
      "            'creative or humorous answer, maybe a joke or a riddle.\\n'\n",
      "            '\\n'\n",
      "            'I should consider the context. The user might be playing with '\n",
      "            'words or testing my knowledge',\n",
      " 'role': 'assistant'}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the pipeline\n",
    "pipe = pipeline(\"text-generation\", \"HuggingFaceTB/SmolLM3-3B\", device_map=\"auto\")\n",
    "\n",
    "# Define your conversation\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a friendly chatbot who always responds in the style of a pirate\"},\n",
    "    {\"role\": \"user\", \"content\": \"How many helicopters can a human eat in one sitting?\"},\n",
    "]\n",
    "\n",
    "# Generate response - pipeline handles chat templates automatically\n",
    "response = pipe(messages, max_new_tokens=128, temperature=0.7)\n",
    "pprint.pprint(response[0]['generated_text'][-1])  # Print the assistant's response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffae9dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final conversation:\n",
      "system: You are a helpful math tutor.\n",
      "user: Can you help me with calculus?\n",
      "assistant: <think>\n",
      "Okay, the user asked for help with calculus. Let me start by understanding what they might need. Calculus is a broad subject that includes differential and integral calculus. Since they didn't specify which area, I should probably ask for more details to provide accurate assistance.\n",
      "\n",
      "First, maybe they're struggling with limits, derivatives, or integrals. Or perhaps they have a specific problem in mind. It's important not to assume their exact needs but to guide them towards identifying their focus areas.\n",
      "\n",
      "I should also consider common problems students face in calculus, such as finding derivatives of functions, applying the chain rule, integrating basic functions like polynomials, trigonometric functions, etc. Maybe they need help with related rates, optimization problems, or curve sketching using derivatives and critical points.\n",
      "\n",
      "Another angle could be multivariable calculus, like partial derivatives, gradients, double integrals, or surface integrals. But without knowing their current level or the topics covered in their course, it's hard to say\n",
      "user: What is a derivative?\n",
      "assistant: <think>\n",
      "Okay, so the user is asking about derivatives in calculus. Let me break this down step by step. A derivative measures how a function changes when its input changes. In simpler terms, if you have a function that describes something over time or space, the derivative tells you the rate at which it's changing at any given point.\n",
      "\n",
      "For example, imagine a car moving along a road. The position of the car can be described by a function called distance versus time (s(t)). The derivative of this function would give the speed of the car at any moment because speed is the rate of change of position with respect to time. Similarly, velocity is the first derivative of position with respect to time, and acceleration is the derivative of velocity with respect to time.\n",
      "\n",
      "Mathematically, the derivative of a function f(x) is denoted as f'(x) or df/dx. The process of finding a derivative involves looking at the slope of the tangent line to the graph of the function at\n"
     ]
    }
   ],
   "source": [
    "# Configure generation parameters\n",
    "generation_config = {\n",
    "    \"max_new_tokens\": 200,\n",
    "    \"temperature\": 0.8,\n",
    "    \"do_sample\": True,\n",
    "    \"top_p\": 0.9,\n",
    "    \"repetition_penalty\": 1.1\n",
    "}\n",
    "\n",
    "# Multi-turn conversation\n",
    "conversation = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful math tutor.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you help me with calculus?\"},\n",
    "]\n",
    "\n",
    "# Generate first response\n",
    "response = pipe(conversation, **generation_config)\n",
    "conversation = response[0]['generated_text']\n",
    "\n",
    "# Continue the conversation\n",
    "conversation.append({\"role\": \"user\", \"content\": \"What is a derivative?\"})\n",
    "response = pipe(conversation, **generation_config)\n",
    "\n",
    "print(\"Final conversation:\")\n",
    "for message in response[0]['generated_text']:\n",
    "    print(f\"{message['role']}: {message['content']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b9bafac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "## Metadata\n",
      "\n",
      "Knowledge Cutoff Date: June 2025\n",
      "Today Date: 23 December 2025\n",
      "Reasoning Mode: /think\n",
      "\n",
      "## Custom Instructions\n",
      "\n",
      "You are a helpful assistant focused on technical topics.\n",
      "\n",
      "<|im_start|>user\n",
      "Can you explain what a chat template is?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "A chat template structures conversations between users and AI models by providing a consistent format that helps the model understand different roles and maintain context.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load SmolLM3's tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceTB/SmolLM3-3B\")\n",
    "\n",
    "# Structure your conversation as a list of message dictionaries\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant focused on technical topics.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you explain what a chat template is?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"A chat template structures conversations between users and AI models by providing a consistent format that helps the model understand different roles and maintain context.\"}\n",
    "]\n",
    "\n",
    "# Apply the chat template\n",
    "formatted_chat = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,  # Return string instead of tokens\n",
    "    add_generation_prompt=True  # Add prompt for next assistant response\n",
    ")\n",
    "\n",
    "print(formatted_chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe7c5b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without generation prompt:\n",
      "<|im_start|>system\n",
      "## Metadata\n",
      "\n",
      "Knowledge Cutoff Date: June 2025\n",
      "Today Date: 23 December 2025\n",
      "Reasoning Mode: /think\n",
      "\n",
      "## Custom Instructions\n",
      "\n",
      "You are a helpful AI assistant named SmolLM, trained by Hugging Face. Your role as an assistant involves thoroughly exploring questions through a systematic thinking process before providing the final precise and accurate solutions. This requires engaging in a comprehensive cycle of analysis, summarizing, exploration, reassessment, reflection, backtracking, and iteration to develop well-considered thinking process. Please structure your response into two main sections: Thought and Solution using the specified format: <think> Thought section </think> Solution section. In the Thought section, detail your reasoning process in steps. Each step should include detailed considerations such as analysing questions, summarizing relevant findings, brainstorming new ideas, verifying the accuracy of the current steps, refining any errors, and revisiting previous steps. In the Solution section, based on various attempts, explorations, and reflections from the Thought section, systematically present the final solution that you deem correct. The Solution section should be logical, accurate, and concise and detail necessary steps needed to reach the conclusion.\n",
      "\n",
      "<|im_start|>user\n",
      "Hi there!<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Nice to meet you!<|im_end|>\n",
      "<|im_start|>user\n",
      "Can I ask a question?<|im_end|>\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "With generation prompt:\n",
      "<|im_start|>system\n",
      "## Metadata\n",
      "\n",
      "Knowledge Cutoff Date: June 2025\n",
      "Today Date: 23 December 2025\n",
      "Reasoning Mode: /think\n",
      "\n",
      "## Custom Instructions\n",
      "\n",
      "You are a helpful AI assistant named SmolLM, trained by Hugging Face. Your role as an assistant involves thoroughly exploring questions through a systematic thinking process before providing the final precise and accurate solutions. This requires engaging in a comprehensive cycle of analysis, summarizing, exploration, reassessment, reflection, backtracking, and iteration to develop well-considered thinking process. Please structure your response into two main sections: Thought and Solution using the specified format: <think> Thought section </think> Solution section. In the Thought section, detail your reasoning process in steps. Each step should include detailed considerations such as analysing questions, summarizing relevant findings, brainstorming new ideas, verifying the accuracy of the current steps, refining any errors, and revisiting previous steps. In the Solution section, based on various attempts, explorations, and reflections from the Thought section, systematically present the final solution that you deem correct. The Solution section should be logical, accurate, and concise and detail necessary steps needed to reach the conclusion.\n",
      "\n",
      "<|im_start|>user\n",
      "Hi there!<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Nice to meet you!<|im_end|>\n",
      "<|im_start|>user\n",
      "Can I ask a question?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceTB/SmolLM3-3B\")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Hi there!\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Nice to meet you!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can I ask a question?\"}\n",
    "]\n",
    "\n",
    "# Without generation prompt - for completed conversations\n",
    "formatted_without = tokenizer.apply_chat_template(\n",
    "    messages, \n",
    "    tokenize=False, \n",
    "    add_generation_prompt=False\n",
    ")\n",
    "\n",
    "print(\"Without generation prompt:\")\n",
    "print(formatted_without)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# With generation prompt - for inference\n",
    "formatted_with = tokenizer.apply_chat_template(\n",
    "    messages, \n",
    "    tokenize=False, \n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "print(\"With generation prompt:\")\n",
    "print(formatted_with)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b79332ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard mode:\n",
      "<|im_start|>system\n",
      "## Metadata\n",
      "\n",
      "Knowledge Cutoff Date: June 2025\n",
      "Today Date: 23 December 2025\n",
      "Reasoning Mode: /think\n",
      "\n",
      "## Custom Instructions\n",
      "\n",
      "You are a helpful AI assistant named SmolLM, trained by Hugging Face. Your role as an assistant involves thoroughly exploring questions through a systematic thinking process before providing the final precise and accurate solutions. This requires engaging in a comprehensive cycle of analysis, summarizing, exploration, reassessment, reflection, backtracking, and iteration to develop well-considered thinking process. Please structure your response into two main sections: Thought and Solution using the specified format: <think> Thought section </think> Solution section. In the Thought section, detail your reasoning process in steps. Each step should include detailed considerations such as analysing questions, summarizing relevant findings, brainstorming new ideas, verifying the accuracy of the current steps, refining any errors, and revisiting previous steps. In the Solution section, based on various attempts, explorations, and reflections from the Thought section, systematically present the final solution that you deem correct. The Solution section should be logical, accurate, and concise and detail necessary steps needed to reach the conclusion.\n",
      "\n",
      "<|im_start|>user\n",
      "What is 15 × 24?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "15 × 24 = 360<|im_end|>\n",
      "\n",
      "\n",
      "Thinking mode:\n",
      "<|im_start|>system\n",
      "## Metadata\n",
      "\n",
      "Knowledge Cutoff Date: June 2025\n",
      "Today Date: 23 December 2025\n",
      "Reasoning Mode: /think\n",
      "\n",
      "## Custom Instructions\n",
      "\n",
      "You are a helpful AI assistant named SmolLM, trained by Hugging Face. Your role as an assistant involves thoroughly exploring questions through a systematic thinking process before providing the final precise and accurate solutions. This requires engaging in a comprehensive cycle of analysis, summarizing, exploration, reassessment, reflection, backtracking, and iteration to develop well-considered thinking process. Please structure your response into two main sections: Thought and Solution using the specified format: <think> Thought section </think> Solution section. In the Thought section, detail your reasoning process in steps. Each step should include detailed considerations such as analysing questions, summarizing relevant findings, brainstorming new ideas, verifying the accuracy of the current steps, refining any errors, and revisiting previous steps. In the Solution section, based on various attempts, explorations, and reflections from the Thought section, systematically present the final solution that you deem correct. The Solution section should be logical, accurate, and concise and detail necessary steps needed to reach the conclusion.\n",
      "\n",
      "<|im_start|>user\n",
      "What is 15 × 24?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<|thinking|>\n",
      "I need to multiply 15 by 24. Let me break this down:\n",
      "15 × 24 = 15 × (20 + 4) = (15 × 20) + (15 × 4) = 300 + 60 = 360\n",
      "</|thinking|>\n",
      "\n",
      "15 × 24 = 360<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Standard mode - direct answer\n",
    "standard_messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is 15 × 24?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"15 × 24 = 360\"}\n",
    "]\n",
    "\n",
    "# Thinking mode - show reasoning process\n",
    "thinking_messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is 15 × 24?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"<|thinking|>\\nI need to multiply 15 by 24. Let me break this down:\\n15 × 24 = 15 × (20 + 4) = (15 × 20) + (15 × 4) = 300 + 60 = 360\\n</|thinking|>\\n\\n15 × 24 = 360\"}\n",
    "]\n",
    "\n",
    "# Apply templates\n",
    "standard_formatted = tokenizer.apply_chat_template(standard_messages, tokenize=False)\n",
    "thinking_formatted = tokenizer.apply_chat_template(thinking_messages, tokenize=False)\n",
    "\n",
    "print(\"Standard mode:\")\n",
    "print(standard_formatted)\n",
    "print(\"\\nThinking mode:\")\n",
    "print(thinking_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e86a3185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_thinking_example(question, answer, reasoning=None):\n",
    "    \"\"\"Create a training example with optional thinking\"\"\"\n",
    "    if reasoning:\n",
    "        assistant_content = f\"<|thinking|>\\n{reasoning}\\n</|thinking|>\\n\\n{answer}\"\n",
    "    else:\n",
    "        assistant_content = answer\n",
    "    \n",
    "    return [\n",
    "        {\"role\": \"user\", \"content\": question},\n",
    "        {\"role\": \"assistant\", \"content\": assistant_content}\n",
    "    ]\n",
    "\n",
    "# Example usage\n",
    "math_example = create_thinking_example(\n",
    "    question=\"What is the derivative of x²?\",\n",
    "    answer=\"The derivative of x² is 2x\",\n",
    "    reasoning=\"Using the power rule: d/dx(x^n) = n·x^(n-1)\\nFor x²: n=2, so d/dx(x²) = 2·x^(2-1) = 2x\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9cc01b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'What is the derivative of x²?'},\n",
       " {'role': 'assistant',\n",
       "  'content': '<|thinking|>\\nUsing the power rule: d/dx(x^n) = n·x^(n-1)\\nFor x²: n=2, so d/dx(x²) = 2·x^(2-1) = 2x\\n</|thinking|>\\n\\nThe derivative of x² is 2x'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33019cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define available tools\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Get the current weather for a location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\"\n",
    "                    },\n",
    "                    \"unit\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                        \"description\": \"The temperature unit\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\", \n",
    "        \"function\": {\n",
    "            \"name\": \"calculate\",\n",
    "            \"description\": \"Perform mathematical calculations\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"expression\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Mathematical expression to evaluate\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"expression\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c69dcfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat template with tools:\n",
      "<|im_start|>system\n",
      "## Metadata\n",
      "\n",
      "Knowledge Cutoff Date: June 2025\n",
      "Today Date: 23 December 2025\n",
      "Reasoning Mode: /think\n",
      "\n",
      "## Custom Instructions\n",
      "\n",
      "You are a helpful assistant with access to tools.\n",
      "\n",
      "### Tools\n",
      "\n",
      "You may call one or more functions to assist with the user query.\n",
      "You are provided with function signatures within <tools></tools> XML tags:\n",
      "\n",
      "<tools>\n",
      "{'type': 'function', 'function': {'name': 'get_weather', 'description': 'Get the current weather for a location', 'parameters': {'type': 'object', 'properties': {'location': {'type': 'string', 'description': 'The city and state, e.g. San Francisco, CA'}, 'unit': {'type': 'string', 'enum': ['celsius', 'fahrenheit'], 'description': 'The temperature unit'}}, 'required': ['location']}}}\n",
      "{'type': 'function', 'function': {'name': 'calculate', 'description': 'Perform mathematical calculations', 'parameters': {'type': 'object', 'properties': {'expression': {'type': 'string', 'description': 'Mathematical expression to evaluate'}}, 'required': ['expression']}}}\n",
      "</tools>\n",
      "\n",
      "For each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\n",
      "<tool_call>\n",
      "{\"name\": <function-name>, \"arguments\": <args-json-object>}\n",
      "</tool_call>\n",
      "\n",
      "<|im_end|>\n",
      "<|im_start|>user\n",
      "What's the weather like in Paris?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "I'll check the weather in Paris for you.<|im_end|>\n",
      "<|im_start|>user\n",
      "{\"temperature\": 22, \"condition\": \"sunny\", \"humidity\": 60}<|im_end|>\n",
      "<|im_start|>assistant\n",
      "The weather in Paris is currently sunny with a temperature of 22°C and 60% humidity. It's a beautiful day!<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Conversation with tool usage\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant with access to tools.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's the weather like in Paris?\"},\n",
    "    {\n",
    "        \"role\": \"assistant\", \n",
    "        \"content\": \"I'll check the weather in Paris for you.\",\n",
    "        \"tool_calls\": [\n",
    "            {\n",
    "                \"id\": \"call_1\",\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"get_weather\",\n",
    "                    \"arguments\": '{\"location\": \"Paris, France\", \"unit\": \"celsius\"}'\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"tool\",\n",
    "        \"tool_call_id\": \"call_1\", \n",
    "        \"content\": '{\"temperature\": 22, \"condition\": \"sunny\", \"humidity\": 60}'\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"The weather in Paris is currently sunny with a temperature of 22°C and 60% humidity. It's a beautiful day!\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Apply chat template with tools\n",
    "formatted_with_tools = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tools=tools,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=False\n",
    ")\n",
    "\n",
    "print(\"Chat template with tools:\")\n",
    "print(formatted_with_tools)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
